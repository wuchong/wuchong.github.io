<!doctype html>



  


<html class="theme-next mist use-motion">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css">


    <meta name="author" content="WuChong">



  <meta name="keywords" content="爬虫,scrapy,动态,配置">





  <link rel="alternate" href="/atom.xml" title="Jark's Blog" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0">






<meta name="description" content="在上一篇博客中我们讲解了如何使用编程的方式运行Scrapy spider。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据">
<meta name="keywords" content="爬虫,scrapy,动态,配置">
<meta property="og:type" content="article">
<meta property="og:title" content="使用Scrapy定制可动态配置的爬虫">
<meta property="og:url" content="http://wuchong.me/blog/2015/05/22/running-scrapy-dynamic-and-configurable/index.html">
<meta property="og:site_name" content="Jark&#39;s Blog">
<meta property="og:description" content="在上一篇博客中我们讲解了如何使用编程的方式运行Scrapy spider。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2022-08-03T06:46:44.511Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="使用Scrapy定制可动态配置的爬虫">
<meta name="twitter:description" content="在上一篇博客中我们讲解了如何使用编程的方式运行Scrapy spider。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 4141040,
      author: '博主'
    }
  };
</script>

  <title> 使用Scrapy定制可动态配置的爬虫 | Jark's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Jark's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">当你的才华还撑不起你的野心时，你就应该静下心来学习。</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-talks">
          <a href="/talks" rel="section">
            
              <i class="menu-item-icon fa fa-microphone-stand fa-fw"></i> <br>
            
            演讲
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br>
            
            关于
          </a>
        </li>
      

      
      
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input">
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', '8Exkz7xsCTJyyCHiK9TY','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                使用Scrapy定制可动态配置的爬虫
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-05-22T22:22:20+08:00" content="2015-05-22">
              2015-05-22
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/程序设计/" itemprop="url" rel="index">
                    <span itemprop="name">程序设计</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/blog/2015/05/22/running-scrapy-dynamic-and-configurable/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="blog/2015/05/22/running-scrapy-dynamic-and-configurable/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    

<!--
    
      <div class="post-body">
    
    -->


    <div class="post-body" itemprop="articleBody">
    

      
      

      
        <p>本文紧接上篇<a href="/blog/2015/05/22/running-scrapy-programmatically">博客</a>，在上一篇博客中我们讲解了如何使用编程的方式运行Scrapy spider。本文将讲解如何通过维护多个网站的爬取规则来抓取各个网站的数据。</p>
<p>具体要实现的目标是这样的，有一张<code>Rule</code>表用来存储各个网站的爬取规则，Scrapy获取<code>Rule</code>表中的记录后，针对每一条rule自动生成一个spider，每个spider去爬它们各自网站的数据。这样我们只需要维护Rule表中的规则（可以写个Web程序来维护），而不用针对上千个网站写上千个spider文件了。</p>
<p>我们使用 <a href="http://www.sqlalchemy.org/" target="_blank" rel="noopener">SQLAlchemy</a> 来映射数据库，Rule表的结构如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> Column, String , DateTime, Integer</span><br><span class="line"><span class="keyword">from</span> sqlalchemy.ext.declarative <span class="keyword">import</span> declarative_base</span><br><span class="line"></span><br><span class="line">Base = declarative_base()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rule</span><span class="params">(Base)</span>:</span></span><br><span class="line">    __tablename__ = <span class="string">'rules'</span></span><br><span class="line"></span><br><span class="line">    id = Column(Integer, primary_key=<span class="literal">True</span>)</span><br><span class="line">    name = Column(String)</span><br><span class="line">    allow_domains = Column(String)</span><br><span class="line">    start_urls = Column(String)</span><br><span class="line">    next_page = Column(String)</span><br><span class="line">    allow_url = Column(String)</span><br><span class="line">    extract_from = Column(String)</span><br><span class="line">    title_xpath = Column(String)</span><br><span class="line">    body_xpath = Column(String)</span><br><span class="line">    publish_time_xpath = Column(String)</span><br><span class="line">    source_site_xpath = Column(String)</span><br><span class="line">    enable = Column(Integer)</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>接下来我们要重新定制我们的spider，命名为<code>DeepSpider</code>，让他能够通过rule参数初始化。我们令<code>DeepSpider</code>继承自 <a href="https://scrapy-chs.readthedocs.org/zh_CN/0.24/topics/spiders.html#crawlspider" target="_blank" rel="noopener"><code>CrawlSpider</code></a>，一个提供了更多强大的规则(rule)来提供跟进link功能的类。<code>deep_spider.py</code>长这个样子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Article</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    body = scrapy.Field()</span><br><span class="line">    publish_time = scrapy.Field()</span><br><span class="line">    source_site = scrapy.Field()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">"Deep"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,rule)</span>:</span></span><br><span class="line">        self.rule = rule</span><br><span class="line">        self.name = rule.name</span><br><span class="line">        self.allowed_domains = rule.allow_domains.split(<span class="string">","</span>)</span><br><span class="line">        self.start_urls = rule.start_urls.split(<span class="string">","</span>)</span><br><span class="line">        rule_list = []</span><br><span class="line">        <span class="comment">#添加`下一页`的规则</span></span><br><span class="line">        <span class="keyword">if</span> rule.next_page:</span><br><span class="line">            rule_list.append(Rule(LinkExtractor(restrict_xpaths = rule.next_page)))</span><br><span class="line">        <span class="comment">#添加抽取文章链接的规则</span></span><br><span class="line">        rule_list.append(Rule(LinkExtractor(</span><br><span class="line">            allow=[rule.allow_url],</span><br><span class="line">            restrict_xpaths = [rule.extract_from]),</span><br><span class="line">            callback=<span class="string">'parse_item'</span>))</span><br><span class="line">        self.rules = tuple(rule_list)</span><br><span class="line">        super(DeepSpider, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.log(<span class="string">'Hi, this is an article page! %s'</span> % response.url)</span><br><span class="line"></span><br><span class="line">        article = Article()</span><br><span class="line"></span><br><span class="line">        article[<span class="string">"url"</span>] = response.url</span><br><span class="line"></span><br><span class="line">        title = response.xpath(self.rule.title_xpath).extract()</span><br><span class="line">        article[<span class="string">"title"</span>] = title[<span class="number">0</span>] <span class="keyword">if</span> title <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        body = response.xpath(self.rule.body_xpath).extract()</span><br><span class="line">        article[<span class="string">"body"</span>] =  <span class="string">'\n'</span>.join(body) <span class="keyword">if</span> body <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        publish_time = response.xpath(self.rule.publish_time_xpath).extract()</span><br><span class="line">        article[<span class="string">"publish_time"</span>] = publish_time[<span class="number">0</span>] <span class="keyword">if</span> publish_time <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        source_site = response.xpath(self.rule.source_site_xpath).extract()</span><br><span class="line">        article[<span class="string">"source_site"</span>] = source_site[<span class="number">0</span>] <span class="keyword">if</span> source_site <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> article</span><br></pre></td></tr></table></figure>
<p>要注意的是<code>start_urls</code>，<code>rules</code>等都初始化成了对象的属性，都由传入的<code>rule</code>对象初始化，<code>parse_item</code>方法中的抽取规则也都有<code>rule</code>对象提供。</p>
<p>为了同时运行多个spider，我们需要稍稍修改上节中的运行脚本<code>run.py</code>，如下所示：</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> spiders.deep_spider import DeepSpider</span><br><span class="line"><span class="keyword">from</span> model.config import DBSession</span><br><span class="line"><span class="keyword">from</span> model.rule import Rule</span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy api</span></span><br><span class="line"><span class="keyword">from</span> scrapy import signals, log</span><br><span class="line"><span class="keyword">from</span> twisted.internet import reactor</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler import Crawler</span><br><span class="line"><span class="keyword">from</span> scrapy.settings import Settings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RUNNING_CRAWLERS = []</span><br><span class="line"></span><br><span class="line">def spider_closing(spider):</span><br><span class="line">    <span class="string">""</span><span class="string">"Activates on spider closed signal"</span><span class="string">""</span></span><br><span class="line">    log.msg(<span class="string">"Spider closed: %s"</span> % spider, <span class="attribute">level</span>=log.INFO)</span><br><span class="line">    RUNNING_CRAWLERS.<span class="builtin-name">remove</span>(spider)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> RUNNING_CRAWLERS:</span><br><span class="line">        reactor.stop()</span><br><span class="line"></span><br><span class="line">log.start(<span class="attribute">loglevel</span>=log.DEBUG)</span><br><span class="line"></span><br><span class="line">settings = Settings()</span><br><span class="line"></span><br><span class="line"><span class="comment"># crawl settings</span></span><br><span class="line">settings.<span class="builtin-name">set</span>(<span class="string">"USER_AGENT"</span>, <span class="string">"Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36"</span>)</span><br><span class="line"></span><br><span class="line">db = DBSession()</span><br><span class="line">rules = db.query(Rule).filter(Rule.<span class="builtin-name">enable</span> == 1)</span><br><span class="line"><span class="keyword">for</span> rule <span class="keyword">in</span> rules:</span><br><span class="line">    crawler = Crawler(settings)</span><br><span class="line">    spider = DeepSpider(rule)  # instantiate every spider using rule</span><br><span class="line">    RUNNING_CRAWLERS.append(spider)</span><br><span class="line"></span><br><span class="line">    # stop reactor when spider closes</span><br><span class="line">    crawler.signals.connect(spider_closing, <span class="attribute">signal</span>=signals.spider_closed)</span><br><span class="line">    crawler.configure()</span><br><span class="line">    crawler.crawl(spider)</span><br><span class="line">    crawler.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># blocks process so always keep as the last statement</span></span><br><span class="line">reactor.<span class="builtin-name">run</span>()</span><br></pre></td></tr></table></figure>
<p>我们从数据库中查出启用的rules，并对于rules中每一个规则实例化一个<code>DeepSpider</code>对象。这儿的一个小技巧是建立了一个<code>RUNNING_CRAWLERS</code>列表，新建立的<code>DeepSpider</code>对象 spider 都会加入这个队列。在 spider 运行完毕时会调用<code>spider_closing</code>方法，并将该spider从<code>RUNNING_CRAWLERS</code>移除。最终，<code>RUNNING_CRAWLERS</code>中没有任何spider了，我们会停止脚本。</p>
<p>运行<code>run.py</code>后，就能对Rule表中网站进行爬取了，但是我们现在还没有对爬下来的结果进行存储，所以看不到结果。下一篇<a href="/blog/2015/05/22/using-redis-and-sqlalchemy-to-checkd-dup-and-store-scrapy-item">博客</a>，我们将使用 Scrapy 提供的强大的 Pipline 对数据进行保存并去重。</p>
<p>现在我们可以往Rule表中加入成百上千个网站的规则，而不用添加一行代码，就可以对这成百上千个网站进行爬取。当然你完全可以做一个Web前端来完成维护Rule表的任务。当然Rule规则也可以放在除了数据库的任何地方，比如配置文件。</p>
<p><em>由于本人刚接触 Scrapy 不久，如有理解不当之处或是更好的解决方案，还请不吝赐教 :)</em></p>
<p>你可以在 <a href="https://github.com/wuchong/scrapy-dynamic-configurable/tree/scrapy-0.24" target="_blank" rel="noopener">GitHub</a> 上看到本文的完整项目。</p>
<p><em>注：本文使用的 Scrapy 版本是 0.24，<a href="https://github.com/wuchong/scrapy-dynamic-configurable" target="_blank" rel="noopener">GitHub</a> 上的master分支已支持 Scrapy 1.0</em></p>
<p><strong>本系列的三篇文章</strong></p>
<ol>
<li><a href="/blog/2015/05/22/running-scrapy-programmatically">编程方式下运行 Scrapy spider</a></li>
<li><a href="/blog/2015/05/22/running-scrapy-dynamic-and-configurable">使用Scrapy定制可动态配置的爬虫</a></li>
<li><a href="/blog/2015/05/22/using-redis-and-sqlalchemy-to-checkd-dup-and-store-scrapy-item">使用Redis和SQLAlchemy对Scrapy Item去重并存储</a></li>
</ol>
<p>###参考资料</p>
<ul>
<li><a href="http://kirankoduru.github.io/python/multiple-scrapy-spiders.html" target="_blank" rel="noopener">Running multiple scrapy spiders programmatically</a></li>
</ul>

      
    </div>

    <div>
      
        
        
<hr>
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
  <img id="wechat_subscriber_qcode" src="https://user-images.githubusercontent.com/5378924/221934214-4ca3bc5d-6d38-4a4a-a6bc-a1dd53563879.png" alt="hoxis wechat" style="width: auto; height:200px; max-width: 100%;">
</div>
<div class="copyright-txt">
  <a href="/copyright"><i class="fa fa-copyright"></i>著作权归作者所有</a>
</div>

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/爬虫/" rel="tag">#爬虫</a>
          
            <a href="/tags/scrapy/" rel="tag">#scrapy</a>
          
        </div>
      

      
      <div class="post-spread">
        
          <!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-56d648eefec3350b" async="async"></script>
<!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_sharing_toolbox"></div>
        
      </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2015/05/22/running-scrapy-programmatically/" rel="next" title="编程方式下运行 Scrapy spider">
                <i class="fa fa-chevron-left"></i> 编程方式下运行 Scrapy spider
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2015/05/22/using-redis-and-sqlalchemy-to-checkd-dup-and-store-scrapy-item/" rel="prev" title="使用Redis和SQLAlchemy对Scrapy Item去重并存储">
                使用Redis和SQLAlchemy对Scrapy Item去重并存储 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/default_avatar.jpg" alt="WuChong">
          <p class="site-author-name" itemprop="name">WuChong</p>
          <p class="site-description motion-element" itemprop="description">当你的才华还撑不起你的野心时，<br>你就应该静下心来学习。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">89</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

<!--
          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">12</span>
              <span class="site-state-item-name">分类</span>
            </a>
          </div>
          -->

          
          
          
            <div class="site-state-item site-state-categories">
              
              <a href="/categories">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">76</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons">
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            <p class="site-author-name">Links</p>
            
              <span class="links-of-author-item">
                <a href="https://flink.apache.org/" target="_blank">Apache Flink</a>
              </span>
            
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <p class="post-toc-empty">此文章未包含目录</p>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WuChong</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  


  



  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.scheme !== 'Pisces' && (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always')) {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'wuchong';
      var disqus_identifier = 'blog/2015/05/22/running-scrapy-dynamic-and-configurable/';
      var disqus_title = '使用Scrapy定制可动态配置的爬虫';
      var disqus_url = 'http://wuchong.me/blog/2015/05/22/running-scrapy-dynamic-and-configurable/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  



  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

  
    <script type="text/javascript" src="http://cdn.staticfile.org/mathjax/2.4.0/MathJax.js"></script>
    <script type="text/javascript" src="http://cdn.staticfile.org/mathjax/2.4.0/config/TeX-AMS-MML_HTMLorMML.js"></script>
  


  
  


</body>
</html>
